{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/joohoshin/TensorflowAI/blob/main/16_2_Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xp0C2anBh3M"
   },
   "source": [
    "마스크 착용여부를 확인하는 모델을 만들어봅시다\n",
    "\n",
    "https://www.kaggle.com/prithwirajmitra/covid-face-mask-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AxzRHuEACgZA"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EEXMMNcpCtNo"
   },
   "outputs": [],
   "source": [
    "data_dir = './New Masks Dataset'\n",
    "img_height = 150\n",
    "img_width = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awH_9AwKsRzh"
   },
   "source": [
    "Image Generator를 사용하여 학습데이터를 늘려봅시다\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AWpeY_YgrYKl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "76YCX9llrB4-"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rg0lLEsiBoHK",
    "outputId": "d4b35913-43b9-4977-e682-957d0397b673"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = train_datagen.flow_from_directory(\n",
    "  data_dir+'/Train',    \n",
    "  target_size=(img_height, img_width),\n",
    "  class_mode = 'binary'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05HMEZgcLKTt",
    "outputId": "e7bc61fa-9b8d-4057-89c2-be6c0c9107d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 306 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir+'/Validation',    \n",
    "  image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1KwZQU58LOcs",
    "outputId": "9ce72087-dded-480b-84a7-cae7b51a6607"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir+'/Test',    \n",
    "  image_size=(img_height, img_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNv__JIPTA2z"
   },
   "source": [
    "pretrained model을 불러와봅시다\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dbr8Ve8wRHMK",
    "outputId": "919a2552-abfb-4613-9695-6e91639fee63"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "vgg_model = VGG16(weights = 'imagenet',include_top=False, input_shape=(150,150,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-KSxs_-fg9DE"
   },
   "outputs": [],
   "source": [
    "vgg_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EI6-2Havh29U",
    "outputId": "8d5fbf36-1b1a-42ae-f090-022ddec73129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 150, 150, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "qHvM0CxJh4Xc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential, Model, layers\n",
    "\n",
    "transfer_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "7eY4QWYgiR2s"
   },
   "outputs": [],
   "source": [
    "transfer_model.add(vgg_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQJCK2_niUP0",
    "outputId": "99a801a3-51e3-4e25-f762-ec97fc71f24a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 2,097,665\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.add(layers.Flatten())\n",
    "transfer_model.add(layers.Dense(256,activation='relu'))\n",
    "transfer_model.add(layers.Dropout(0.5))\n",
    "transfer_model.add(layers.Dense(1,activation='sigmoid'))\n",
    "\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kBAARlrLjRkl",
    "outputId": "4855ffd2-e619-4ffa-af1b-515f3716def7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AA0442D168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AA0442D168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.4689 - acc: 0.8083WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002AA4A5C1D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002AA4A5C1D38> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "19/19 [==============================] - 8s 443ms/step - loss: 0.4689 - acc: 0.8083 - val_loss: 5.3095 - val_acc: 0.9085\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 8s 414ms/step - loss: 0.2621 - acc: 0.8933 - val_loss: 4.4903 - val_acc: 0.9248\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 8s 414ms/step - loss: 0.1429 - acc: 0.9483 - val_loss: 4.6942 - val_acc: 0.9248\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 8s 408ms/step - loss: 0.1176 - acc: 0.9500 - val_loss: 4.5351 - val_acc: 0.9281\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 8s 406ms/step - loss: 0.1053 - acc: 0.9683 - val_loss: 4.9466 - val_acc: 0.9216\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.1067 - acc: 0.9567 - val_loss: 3.6872 - val_acc: 0.9346\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 8s 409ms/step - loss: 0.0788 - acc: 0.9700 - val_loss: 4.0922 - val_acc: 0.9379\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.0913 - acc: 0.9717 - val_loss: 3.8302 - val_acc: 0.9412\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.0773 - acc: 0.9733 - val_loss: 3.4725 - val_acc: 0.9444\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 8s 409ms/step - loss: 0.0608 - acc: 0.9767 - val_loss: 4.4455 - val_acc: 0.9379\n"
     ]
    }
   ],
   "source": [
    "transfer_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "history = transfer_model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RIz02NFzkF49",
    "outputId": "131da3b0-4325-4771-d821-7b808a5147d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  19\n"
     ]
    }
   ],
   "source": [
    "vgg_model.trainable = True\n",
    "\n",
    "# 기본 모델에 몇 개의 층이 있는지 확인 합니다.\n",
    "print(\"Number of layers in the base model: \", len(vgg_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cGQDyFNZuMXI"
   },
   "outputs": [],
   "source": [
    "# 해당 층 이후부터 미세 조정\n",
    "fine_tune_at = 15\n",
    "\n",
    "# `fine_tune_at` 층 이전의 모든 층을 고정\n",
    "for layer in vgg_model.layers[:fine_tune_at]:\n",
    "    layer.trainable =  False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wx9Inufdbnza",
    "outputId": "e39f6f2f-2cd5-49ca-c773-4c70218914e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               2097408   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 16,812,353\n",
      "Trainable params: 9,177,089\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=['acc'])\n",
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "WTVcbHtNk2j9",
    "outputId": "6dcf7aa4-234c-4ff8-a612-d3be862b98df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AA60FA58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000002AA60FA58B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "19/19 [==============================] - ETA: 0s - loss: 0.5486 - acc: 0.8367WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002AA61235E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000002AA61235E58> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "19/19 [==============================] - 8s 418ms/step - loss: 0.5486 - acc: 0.8367 - val_loss: 3.3073 - val_acc: 0.9150\n",
      "Epoch 2/10\n",
      "19/19 [==============================] - 8s 410ms/step - loss: 0.1758 - acc: 0.9300 - val_loss: 12.4821 - val_acc: 0.8987\n",
      "Epoch 3/10\n",
      "19/19 [==============================] - 8s 408ms/step - loss: 0.0767 - acc: 0.9700 - val_loss: 2.0974 - val_acc: 0.9804\n",
      "Epoch 4/10\n",
      "19/19 [==============================] - 8s 408ms/step - loss: 0.0369 - acc: 0.9867 - val_loss: 3.1691 - val_acc: 0.9771\n",
      "Epoch 5/10\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.0187 - acc: 0.9900 - val_loss: 4.2671 - val_acc: 0.9673\n",
      "Epoch 6/10\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.0085 - acc: 0.9967 - val_loss: 4.7274 - val_acc: 0.9804\n",
      "Epoch 7/10\n",
      "19/19 [==============================] - 8s 416ms/step - loss: 0.0114 - acc: 0.9967 - val_loss: 4.6799 - val_acc: 0.9837\n",
      "Epoch 8/10\n",
      "19/19 [==============================] - 8s 410ms/step - loss: 0.0266 - acc: 0.9850 - val_loss: 6.3709 - val_acc: 0.9739\n",
      "Epoch 9/10\n",
      "19/19 [==============================] - 8s 412ms/step - loss: 0.0115 - acc: 0.9933 - val_loss: 5.3055 - val_acc: 0.9771\n",
      "Epoch 10/10\n",
      "19/19 [==============================] - 8s 411ms/step - loss: 0.0154 - acc: 0.9950 - val_loss: 4.1871 - val_acc: 0.9869\n"
     ]
    }
   ],
   "source": [
    "history = transfer_model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LO9WRZ4IkPIi"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPAEjNcH2/ZBET9qzvQhnrn",
   "collapsed_sections": [],
   "include_colab_link": true,
   "mount_file_id": "1VPmrhmB0jhFBfo6QvgEwAykr8JEQfQBV",
   "name": "16_2_Fine Tuning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
