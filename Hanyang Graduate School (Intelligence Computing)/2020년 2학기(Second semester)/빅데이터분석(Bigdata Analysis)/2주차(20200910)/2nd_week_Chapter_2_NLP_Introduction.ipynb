{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to\n",
      "[nltk_data]     C:\\Users\\Jae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import names\n",
    "\n",
    "names.words()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "groups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: lerxst@wam.umd.edu (where's my thing)\\nSubject: WHAT car is this!?\\nNntp-Posting-Host: rac3.wam.umd.edu\\nOrganization: University of Maryland, College Park\\nLines: 15\\n\\n I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.\\n\\nThanks,\\n- IL\\n   ---- brought to you by your neighborhood Lerxst ----\\n\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.target[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'everyone', '.', 'Nice', 'to', 'meet', 'you', '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = word_tokenize(\"Hello, everyone. Nice to meet you.\")\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hello', 'NNP'),\n",
       " (',', ','),\n",
       " ('everyone', 'NN'),\n",
       " ('.', '.'),\n",
       " ('Nice', 'NNP'),\n",
       " ('to', 'TO'),\n",
       " ('meet', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos = nltk.pos_tag(tokens)\n",
    "pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "European    \t NORP\n",
      "Google      \t ORG\n",
      "$5.1 billion\t MONEY\n",
      "Wednesday   \t DATE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc = nlp('''European autorities fined Google a record $5.1 billion on Wednesday \\n\n",
    "for abusing its power in the mobile phone market and \n",
    "ordered the company to alter its practices''')\n",
    "\n",
    "for entity in doc.ents:\n",
    "    print('{:12}\\t {}'.format(entity.text, entity.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machin\n",
      "learn\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "print(porter_stemmer.stem('machines'))\n",
    "\n",
    "print(porter_stemmer.stem('learning'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Jae\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('machines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'learning'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '1993',\n",
       " '20',\n",
       " '25',\n",
       " 'article',\n",
       " 'available',\n",
       " 'ax',\n",
       " 'believe',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'ca',\n",
       " 'case',\n",
       " 'com',\n",
       " 'come',\n",
       " 'computer',\n",
       " 'cs',\n",
       " 'data',\n",
       " 'david',\n",
       " 'day',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'distribution',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'don',\n",
       " 'drive',\n",
       " 'edu',\n",
       " 'file',\n",
       " 'god',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'help',\n",
       " 'host',\n",
       " 'information',\n",
       " 'just',\n",
       " 'key',\n",
       " 'know',\n",
       " 'law',\n",
       " 'let',\n",
       " 'like',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'max',\n",
       " 'need',\n",
       " 'new',\n",
       " 'news',\n",
       " 'nntp',\n",
       " 'number',\n",
       " 'organization',\n",
       " 'people',\n",
       " 'point',\n",
       " 'posting',\n",
       " 'power',\n",
       " 'problem',\n",
       " 'program',\n",
       " 'question',\n",
       " 'read',\n",
       " 'really',\n",
       " 'reply',\n",
       " 'right',\n",
       " 'said',\n",
       " 'say',\n",
       " 'software',\n",
       " 'space',\n",
       " 'state',\n",
       " 'subject',\n",
       " 'sure',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'time',\n",
       " 'uk',\n",
       " 'university',\n",
       " 'usa',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 've',\n",
       " 'version',\n",
       " 'want',\n",
       " 'way',\n",
       " 'windows',\n",
       " 'work',\n",
       " 'world',\n",
       " 'writes',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "groups = fetch_20newsgroups()\n",
    "\n",
    "cv = CountVectorizer(max_features=100, stop_words='english')\n",
    "cv_model = cv.fit(groups.data)\n",
    "\n",
    "cv_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result = cv_model.transform(groups.data)\n",
    "\n",
    "cv_result[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '12',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '1993',\n",
       " '20',\n",
       " '25',\n",
       " 'article',\n",
       " 'available',\n",
       " 'ax',\n",
       " 'believe',\n",
       " 'better',\n",
       " 'bit',\n",
       " 'ca',\n",
       " 'case',\n",
       " 'com',\n",
       " 'come',\n",
       " 'computer',\n",
       " 'cs',\n",
       " 'data',\n",
       " 'david',\n",
       " 'day',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'distribution',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'don',\n",
       " 'drive',\n",
       " 'edu',\n",
       " 'file',\n",
       " 'god',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'government',\n",
       " 'help',\n",
       " 'host',\n",
       " 'information',\n",
       " 'just',\n",
       " 'key',\n",
       " 'know',\n",
       " 'law',\n",
       " 'let',\n",
       " 'like',\n",
       " 'lines',\n",
       " 'little',\n",
       " 'll',\n",
       " 'long',\n",
       " 'look',\n",
       " 'mail',\n",
       " 'make',\n",
       " 'max',\n",
       " 'need',\n",
       " 'new',\n",
       " 'news',\n",
       " 'nntp',\n",
       " 'number',\n",
       " 'organization',\n",
       " 'people',\n",
       " 'point',\n",
       " 'posting',\n",
       " 'power',\n",
       " 'problem',\n",
       " 'program',\n",
       " 'question',\n",
       " 'read',\n",
       " 'really',\n",
       " 'reply',\n",
       " 'right',\n",
       " 'said',\n",
       " 'say',\n",
       " 'software',\n",
       " 'space',\n",
       " 'state',\n",
       " 'subject',\n",
       " 'sure',\n",
       " 'thanks',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'time',\n",
       " 'uk',\n",
       " 'university',\n",
       " 'usa',\n",
       " 'use',\n",
       " 'used',\n",
       " 'using',\n",
       " 've',\n",
       " 'version',\n",
       " 'want',\n",
       " 'way',\n",
       " 'windows',\n",
       " 'work',\n",
       " 'world',\n",
       " 'writes',\n",
       " 'year',\n",
       " 'years']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "groups = fetch_20newsgroups()\n",
    "\n",
    "tfidfv = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "tfidfv_model = tfidfv.fit(groups.data)\n",
    "\n",
    "tfidfv_model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.33007844,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.34514661, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.2846696 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18462679,\n",
       "        0.        , 0.        , 0.        , 0.22313225, 0.        ,\n",
       "        0.        , 0.        , 0.10017886, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.31221321, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.18593478, 0.        ,\n",
       "        0.10387649, 0.        , 0.        , 0.17967744, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.29536189,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.09985181, 0.        , 0.28725892,\n",
       "        0.32390007, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.19330566, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.3159845 ]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv_result = tfidfv_model.transform(groups.data)\n",
    "\n",
    "tfidfv_result[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
