{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "data = pd.read_csv('ctr_data_20000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['id','hour','device_id','device_ip'], axis=1)\n",
    "\n",
    "X = data.loc[:, data.columns != 'click'].astype('str')\n",
    "y = data.loc[:, data.columns == 'click'].astype('int').values.ravel()\n",
    "\n",
    "X_dic = X.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "one_hot_encoder = DictVectorizer()\n",
    "\n",
    "onehot_X = one_hot_encoder.fit_transform(X_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4141\n",
      "           1       0.47      0.10      0.17       859\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.65      0.54      0.54      5000\n",
      "weighted avg       0.78      0.83      0.78      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "train_X, test_X = onehot_X[0:15000], onehot_X[15000:]\n",
    "train_y, test_y = y[0:15000], y[15000:]\n",
    "\n",
    "rdf = RandomForestClassifier(n_estimators=100,\n",
    "                             criterion = 'gini',\n",
    "                             min_samples_split=30)\n",
    "\n",
    "rdf.fit(train_X, train_y)\n",
    "\n",
    "prediction = rdf.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4141\n",
      "           1       0.48      0.08      0.14       859\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.66      0.53      0.52      5000\n",
      "weighted avg       0.78      0.83      0.77      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "train_X02, test_X02 = onehot_X[0:15000], onehot_X[15000:]\n",
    "train_y02, test_y02 = y[0:15000], y[15000:]\n",
    "\n",
    "ada_boost = AdaBoostClassifier(n_estimators = 50)\n",
    "ada_boost.fit(train_X02, train_y02)\n",
    "\n",
    "prediction02 = ada_boost.predict(test_X02)\n",
    "\n",
    "print(classification_report(test_y02, prediction02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4141\n",
      "           1       0.48      0.08      0.14       859\n",
      "\n",
      "    accuracy                           0.83      5000\n",
      "   macro avg       0.66      0.53      0.52      5000\n",
      "weighted avg       0.78      0.83      0.77      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "train_X03, test_X03 = onehot_X[0:15000], onehot_X[15000:]\n",
    "train_y03, test_y03 = y[0:15000], y[15000:]\n",
    "\n",
    "gbm = GradientBoostingClassifier()\n",
    "gbm.fit(train_X03, train_y03)\n",
    "\n",
    "prediction03 = gbm.predict(test_X03)\n",
    "\n",
    "print(classification_report(test_y02, prediction02))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\anaconda\\lib\\site-packages (1.2.1)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from xgboost) (1.19.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.98      0.90      4141\n",
      "           1       0.44      0.09      0.15       859\n",
      "\n",
      "    accuracy                           0.82      5000\n",
      "   macro avg       0.64      0.53      0.53      5000\n",
      "weighted avg       0.77      0.82      0.77      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "train_X04, test_X04 = onehot_X[0:15000], onehot_X[15000:]\n",
    "train_y04, test_y04 = y[0:15000], y[15000:]\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(train_X04, train_y04)\n",
    "\n",
    "prediction04 = xgb.predict(test_X04)\n",
    "\n",
    "print(classification_report(test_y04, prediction04))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\anaconda\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in c:\\anaconda\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in c:\\anaconda\\lib\\site-packages (from lightgbm) (1.19.4)\n",
      "Requirement already satisfied: scipy in c:\\anaconda\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_data = lgb.Dataset(train_X, train_y)\n",
    "test_data = lgb.Dataset(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004247 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Warning] objective is set=binary, application=binary will be ignored. Current value: objective=binary\n",
      "[1]\tvalid_0's auc: 0.686474\n",
      "[2]\tvalid_0's auc: 0.698008\n",
      "[3]\tvalid_0's auc: 0.705473\n",
      "[4]\tvalid_0's auc: 0.707587\n",
      "[5]\tvalid_0's auc: 0.711021\n",
      "[6]\tvalid_0's auc: 0.712422\n",
      "[7]\tvalid_0's auc: 0.71286\n",
      "[8]\tvalid_0's auc: 0.712578\n",
      "[9]\tvalid_0's auc: 0.713436\n",
      "[10]\tvalid_0's auc: 0.713087\n",
      "[11]\tvalid_0's auc: 0.713639\n",
      "[12]\tvalid_0's auc: 0.713597\n",
      "[13]\tvalid_0's auc: 0.715383\n",
      "[14]\tvalid_0's auc: 0.715502\n",
      "[15]\tvalid_0's auc: 0.715977\n",
      "[16]\tvalid_0's auc: 0.715069\n",
      "[17]\tvalid_0's auc: 0.715158\n",
      "[18]\tvalid_0's auc: 0.71558\n",
      "[19]\tvalid_0's auc: 0.715502\n",
      "[20]\tvalid_0's auc: 0.715871\n",
      "[21]\tvalid_0's auc: 0.716133\n",
      "[22]\tvalid_0's auc: 0.715791\n",
      "[23]\tvalid_0's auc: 0.714979\n",
      "[24]\tvalid_0's auc: 0.714734\n",
      "[25]\tvalid_0's auc: 0.714825\n",
      "[26]\tvalid_0's auc: 0.714656\n",
      "[27]\tvalid_0's auc: 0.713657\n",
      "[28]\tvalid_0's auc: 0.71243\n",
      "[29]\tvalid_0's auc: 0.712365\n",
      "[30]\tvalid_0's auc: 0.712433\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84      4141\n",
      "           1       0.32      0.44      0.37       859\n",
      "\n",
      "    accuracy                           0.75      5000\n",
      "   macro avg       0.60      0.62      0.61      5000\n",
      "weighted avg       0.78      0.75      0.76      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'application': 'binary',\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 31,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.5,\n",
    "    'bagging_freq': 20,\n",
    "    'learning_rate': 0.05,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "num_round = 30\n",
    "\n",
    "lgbm = lgb.train(parameters, train_data, num_round, valid_sets = [test_data])\n",
    "\n",
    "prediction = lgbm.predict(test_X)\n",
    "\n",
    "print(classification_report(test_y, prediction>0.5 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
