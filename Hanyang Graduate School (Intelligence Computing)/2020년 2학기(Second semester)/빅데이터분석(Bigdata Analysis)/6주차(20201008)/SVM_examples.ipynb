{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "groups = fetch_20newsgroups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "all_names = set(names.words())\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(docs):\n",
    "    cleaned_docs = []\n",
    "    for doc in docs:\n",
    "        lemmatized_list = [lemmatizer.lemmatize(word.lower()) for word in doc.split() \n",
    "                           if word.isalpha() and word not in all_names]\n",
    "        cleaned_docs += [' '.join(lemmatized_list)]\n",
    "        \n",
    "    return cleaned_docs\n",
    "\n",
    "cleaned_data = clean_text(groups.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_data,\n",
    "                                                   groups.target,\n",
    "                                                   test_size = 0.2,\n",
    "                                                   random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "groups = fetch_20newsgroups()\n",
    "\n",
    "tfidfv = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "tfidfv_model = tfidfv.fit(X_train)\n",
    "\n",
    "X_train_vec = tfidfv_model.transform(X_train)\n",
    "X_test_vec = tfidfv_model.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.57        88\n",
      "           1       0.59      0.63      0.61       128\n",
      "           2       0.65      0.64      0.64       113\n",
      "           3       0.58      0.53      0.55       128\n",
      "           4       0.60      0.51      0.55       120\n",
      "           5       0.72      0.59      0.65       120\n",
      "           6       0.67      0.67      0.67       105\n",
      "           7       0.77      0.63      0.69       117\n",
      "           8       0.88      0.70      0.78       128\n",
      "           9       0.74      0.84      0.79       119\n",
      "          10       0.96      0.77      0.85       115\n",
      "          11       0.97      0.68      0.80       130\n",
      "          12       0.32      0.82      0.47       122\n",
      "          13       0.59      0.80      0.68        99\n",
      "          14       0.86      0.72      0.79       122\n",
      "          15       0.63      0.83      0.71       127\n",
      "          16       0.86      0.70      0.77       115\n",
      "          17       0.96      0.69      0.80       112\n",
      "          18       0.55      0.82      0.66        80\n",
      "          19       0.00      0.00      0.00        75\n",
      "\n",
      "    accuracy                           0.66      2263\n",
      "   macro avg       0.68      0.65      0.65      2263\n",
      "weighted avg       0.69      0.66      0.66      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.1, random_state=0)\n",
    "\n",
    "svm.fit(X_train_vec, y_train)\n",
    "\n",
    "prediction = svm.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1}\n",
      "0.7068832173240525\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':(0.1, 1)}\n",
    "grid_search = GridSearchCV(svm, parameters, cv=3)\n",
    "\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        88\n",
      "           1       0.63      0.66      0.64       128\n",
      "           2       0.65      0.74      0.69       113\n",
      "           3       0.60      0.59      0.60       128\n",
      "           4       0.58      0.57      0.57       120\n",
      "           5       0.75      0.69      0.72       120\n",
      "           6       0.75      0.72      0.73       105\n",
      "           7       0.69      0.74      0.71       117\n",
      "           8       0.84      0.77      0.80       128\n",
      "           9       0.71      0.84      0.77       119\n",
      "          10       0.90      0.82      0.86       115\n",
      "          11       0.92      0.85      0.88       130\n",
      "          12       0.61      0.71      0.66       122\n",
      "          13       0.74      0.78      0.76        99\n",
      "          14       0.79      0.81      0.80       122\n",
      "          15       0.76      0.81      0.79       127\n",
      "          16       0.86      0.78      0.82       115\n",
      "          17       0.91      0.79      0.85       112\n",
      "          18       0.73      0.71      0.72        80\n",
      "          19       0.71      0.49      0.58        75\n",
      "\n",
      "    accuracy                           0.74      2263\n",
      "   macro avg       0.74      0.73      0.73      2263\n",
      "weighted avg       0.74      0.74      0.74      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = grid_search.best_estimator_\n",
    "prediction = svm_best.predict(X_test_vec)\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words='english',\n",
       "                                                        stri...\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='scale',\n",
       "                                            kernel='linear', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'svc__C': (0.1, 1), 'tfidf__max_df': (0.25, 0.5),\n",
       "                         'tfidf__max_features': (100, 1000)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([('tfidf', TfidfVectorizer(stop_words='english')), ('svc', SVC(kernel='linear'))])\n",
    "\n",
    "parameters_pipeline = {\n",
    "    'tfidf__max_df': (0.25, 0.5),\n",
    "    'tfidf__max_features' : (100, 1000),\n",
    "    'svc__C' : (0.1, 1)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters_pipeline, cv=3)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'tfidf__max_df': 0.5, 'tfidf__max_features': 1000}\n",
      "0.7076566125290022\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        88\n",
      "           1       0.63      0.66      0.64       128\n",
      "           2       0.65      0.74      0.69       113\n",
      "           3       0.60      0.59      0.60       128\n",
      "           4       0.58      0.57      0.57       120\n",
      "           5       0.75      0.69      0.72       120\n",
      "           6       0.75      0.72      0.73       105\n",
      "           7       0.69      0.74      0.71       117\n",
      "           8       0.84      0.77      0.80       128\n",
      "           9       0.71      0.84      0.77       119\n",
      "          10       0.90      0.82      0.86       115\n",
      "          11       0.92      0.85      0.88       130\n",
      "          12       0.61      0.71      0.66       122\n",
      "          13       0.74      0.78      0.76        99\n",
      "          14       0.79      0.81      0.80       122\n",
      "          15       0.76      0.81      0.79       127\n",
      "          16       0.86      0.78      0.82       115\n",
      "          17       0.91      0.79      0.85       112\n",
      "          18       0.73      0.71      0.72        80\n",
      "          19       0.71      0.49      0.58        75\n",
      "\n",
      "    accuracy                           0.74      2263\n",
      "   macro avg       0.74      0.73      0.73      2263\n",
      "weighted avg       0.74      0.74      0.74      2263\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_best = grid_search.best_estimator_\n",
    "prediction = svm_best.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_py37",
   "language": "python",
   "name": "tensorflow2_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
